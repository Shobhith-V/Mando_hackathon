import os
from dotenv import load_dotenv
import google.generativeai as genai
from PIL import Image

# Load environment variables from .env file
load_dotenv()

# Configure Gemini API
GEMINI_API_KEY = "AIzaSyAnfqjCG3sDs3QcopuRXAlGXM2SuIZplS8"
if not GEMINI_API_KEY:
    raise ValueError("Missing GEMINI_API_KEY in .env")

genai.configure(api_key=GEMINI_API_KEY)

# Load models
# Updated model initialization
text_model = genai.GenerativeModel("gemini-2.5-pro-exp-03-25")
vision_model = genai.GenerativeModel("gemini-2.5-pro-exp-03-25")



def answer_question(question, text_chunks, image_files=None):
    """
    Parameters:
        question (str): The user's question.
        text_chunks (List[Tuple[str, str]]): (text, source) chunks for context.
        image_files (List[UploadedFile]): Optional image files from Streamlit uploader.

    Returns:
        str: The answer generated by Gemini.
    """
    context = "\n\n".join([text for text, _ in text_chunks])
    prompt = f"Use the following context to answer this question:\n\n{context}\n\nQ: {question}"

    try:
        if image_files:
            images = [Image.open(img) for img in image_files]
            response = vision_model.generate_content([prompt] + images)
        else:
            response = text_model.generate_content(prompt)

        return response.text.strip()

    except Exception as e:
        return f"⚠️ Gemini API Error: {str(e)}"
